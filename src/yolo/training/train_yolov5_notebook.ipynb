{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a6e35d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0299c5",
   "metadata": {},
   "source": [
    "# 1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Source dataset structure\n",
    "\n",
    "data_categories/\n",
    "\n",
    "    - s_bar_double/\n",
    "        - 0001.png\n",
    "        - 0002.png\n",
    "\n",
    "    - ns_non_school/\n",
    "        - 0002.png\n",
    "        - 0003.png\n",
    "  \n",
    "  \n",
    "label_txt_files/\n",
    "    \n",
    "    - 0001.txt\n",
    "    - 0002.txt\n",
    "    - 0003.txt\n",
    "    - 0004.txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_src = 'data_categories/'\n",
    "label_src_dir = 'label_txt_files' # folder containing yolo format label text files\n",
    "\n",
    "data_cats = os.listdir(data_src)\n",
    "\n",
    "# folders that start with \"s_\" contains school tiles and \"ns_\" non-school tiles\n",
    "school_cats = sorted([i for i in data_cats if i.startswith('s_')])\n",
    "non_school_cats = sorted([i for i in data_cats if i.startswith('ns_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d790e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupt images in dataset\n",
    "corrupt_list = ['42304318_E.png',\n",
    "'61212325.png',\n",
    "'61223303.png',\n",
    "'42201308.png',\n",
    "'41606305_N.png',\n",
    "'11302316_E.png',\n",
    "'23301340_W.png',\n",
    "'11301320_E.png']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9dd72a",
   "metadata": {},
   "source": [
    "## 1.1. Choose which categories to put into training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df1bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please list all the categories that are present in the \"data_categories\" folder\n",
    "# and comment the items you do not want to include in the training dataset\n",
    "\n",
    "school_cats = [\n",
    "    's_bar_adjacent',\n",
    "    's_bar_double',\n",
    "    's_bar_double_1',\n",
    "    's_bar_double_2',\n",
    "    's_bar_double_3',\n",
    "    's_bar_double_4',\n",
    "    # 's_bar_double_short_obvious',\n",
    "    's_bar_multiple',\n",
    "    # 's_bar_single',\n",
    "    's_bar_triple',\n",
    "    's_group_parallel',\n",
    "    's_group_parallel_1',\n",
    "    's_group_parallel_2',\n",
    "    's_group_parallel_3',\n",
    "    's_group_parallel_4',\n",
    "    's_group_parallel_5',\n",
    "    's_shape_C',\n",
    "    's_shape_L',\n",
    "    # 's_shape_O',\n",
    "    's_wings'\n",
    "]\n",
    "\n",
    "non_school_cats = [\n",
    "    'ns_fences',\n",
    "    'ns_fences_1',\n",
    "    'ns_fences_2',\n",
    "    'ns_housings',\n",
    "    'ns_large_buildings',\n",
    "    'ns_like_building',\n",
    "    'ns_non_school',\n",
    "    'ns_plain'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff99d41",
   "metadata": {},
   "source": [
    "## 1.2. Create dataset train / val folders for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training dataset structure\n",
    "\n",
    "dataset/\n",
    "\n",
    "    - train/\n",
    "        - images/\n",
    "            - 0001.png\n",
    "            - 0002.png\n",
    "        - labels/\n",
    "            - 0001.txt\n",
    "            - 0002.txt\n",
    "            \n",
    "    - val/\n",
    "        - images/\n",
    "            - 0003.png\n",
    "            - 0004.png\n",
    "        - labels/\n",
    "            - 0003.txt\n",
    "            - 0004.txt\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb97986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root dir for training dataset\n",
    "dataset_root = 'dataset'\n",
    "val_size = 0.20\n",
    "\n",
    "# create dataset train/val folders\n",
    "train_image_folder = os.path.join(dataset_root, 'train/images')\n",
    "train_label_folder = os.path.join(dataset_root, 'train/labels')\n",
    "val_image_folder = os.path.join(dataset_root, 'val/images')\n",
    "val_label_folder = os.path.join(dataset_root, 'val/labels')\n",
    "\n",
    "os.makedirs(train_image_folder, exist_ok = True)\n",
    "os.makedirs(train_label_folder, exist_ok = True)\n",
    "os.makedirs(val_image_folder, exist_ok = True)\n",
    "os.makedirs(val_label_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7bed96",
   "metadata": {},
   "source": [
    "## 1.3. Copy school images from chosen categories above to training dataset dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for building_type in school_cats:\n",
    "    image_folder = f'{data_src}/{building_type}/*/*'\n",
    "    image_list = glob(image_folder)\n",
    "    image_list = [i for i in image_list if os.path.split(i)[1] not in corrupt_list]\n",
    "    \n",
    "    # split train/val    \n",
    "    train, val = train_test_split(image_list, test_size=val_size, random_state=42)\n",
    "    \n",
    "    print(f'{building_type} : {len(image_list)} = {len(train)} / {len(val)}')\n",
    "    \n",
    "    # copy train data\n",
    "    for src_image in train:\n",
    "        \n",
    "        # copy images\n",
    "        dirname, filename = os.path.split(src_image)\n",
    "        dst_image = os.path.join(train_image_folder, filename)\n",
    "        shutil.copy(src_image, dst_image)\n",
    "        \n",
    "        # copy labels\n",
    "        label_dst_dir = train_label_folder\n",
    "        src_label = os.path.join(label_src_dir, filename.replace('.png', '.txt'))\n",
    "        dst_label = os.path.join(label_dst_dir, filename.replace('.png', '.txt'))\n",
    "        shutil.copy(src_label, dst_label)\n",
    "        \n",
    "    # copy val data\n",
    "    for src_image in val:\n",
    "        \n",
    "        # copy images\n",
    "        dirname, filename = os.path.split(src_image)\n",
    "        dst_image = os.path.join(val_image_folder, filename)\n",
    "        shutil.copy(src_image, dst_image)\n",
    "        \n",
    "        # copy labels\n",
    "        label_dst_dir = val_label_folder\n",
    "        src_label = os.path.join(label_src_dir, filename.replace('.png', '.txt'))\n",
    "        dst_label = os.path.join(label_dst_dir, filename.replace('.png', '.txt'))\n",
    "        shutil.copy(src_label, dst_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b682e92",
   "metadata": {},
   "source": [
    "## 1.4. Copy non-school images to training dataset dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for non_school_type in non_school_cats:\n",
    "    image_folder = f'{data_src}/{non_school_type}/*/*'\n",
    "    \n",
    "    image_list = glob(image_folder)\n",
    "    image_list = [i for i in image_list if os.path.split(i)[1] not in corrupt_list]\n",
    "    \n",
    "    # split train/val    \n",
    "    train, val = train_test_split(image_list, test_size=val_size, random_state=42)\n",
    "    \n",
    "    print(f'{non_school_type} : {len(image_list)} = {len(train)} / {len(val)}')\n",
    "    \n",
    "    # copy train data\n",
    "    for src_image in train:\n",
    "        \n",
    "        # copy images\n",
    "        dirname, filename = os.path.split(src_image)\n",
    "        dst_image = os.path.join(train_image_folder, filename)\n",
    "        shutil.copy(src_image, dst_image)\n",
    "                \n",
    "        # create new label txt files\n",
    "        label_dst_dir = train_label_folder\n",
    "        dst_label = os.path.join(label_dst_dir, filename.replace('.png', '.txt'))\n",
    "        \n",
    "        # write new label txt file\n",
    "        content = ''\n",
    "        with open(dst_label, 'w') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "    # copy val data\n",
    "    for src_image in val:\n",
    "        \n",
    "        # copy images\n",
    "        dirname, filename = os.path.split(src_image)\n",
    "        dst_image = os.path.join(val_image_folder, filename)\n",
    "        shutil.copy(src_image, dst_image)\n",
    "        \n",
    "        # create new label txt files\n",
    "        label_dst_dir = val_label_folder\n",
    "        dst_label = os.path.join(label_dst_dir, filename.replace('.png', '.txt'))\n",
    "        \n",
    "        # write new blank label txt file\n",
    "        content = ''\n",
    "        with open(dst_label, 'w') as f:\n",
    "            f.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e80b26",
   "metadata": {},
   "source": [
    "## 1.5. Training dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################   assertion   ####################\n",
    "train_img_ids = [os.path.splitext(i)[0] for i in os.listdir(train_image_folder)]\n",
    "train_label_ids = [os.path.splitext(i)[0] for i in os.listdir(train_label_folder)]\n",
    "\n",
    "val_img_ids = [os.path.splitext(i)[0] for i in os.listdir(val_image_folder)]\n",
    "val_label_ids =[os.path.splitext(i)[0] for i in os.listdir(val_label_folder)]\n",
    "\n",
    "intersection = list(set(train_img_ids) & set(train_label_ids))\n",
    "assert(len(train_img_ids) == len(intersection))\n",
    "\n",
    "intersection = list(set(val_img_ids) & set(val_label_ids))\n",
    "assert(len(val_img_ids) == len(intersection))\n",
    "\n",
    "\n",
    "####################   stats   ####################\n",
    "train_labels = glob(os.path.join(train_label_folder, '*'))\n",
    "val_labels = glob(os.path.join(val_label_folder, '*'))\n",
    "\n",
    "non_school_train, non_school_val = 0, 0\n",
    "school_train, school_val = 0, 0\n",
    "\n",
    "for item in train_labels:\n",
    "    with open(item, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    if len(data) == 0: non_school_train += 1\n",
    "    else: school_train += 1\n",
    "        \n",
    "for item in val_labels:\n",
    "    with open(item, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    if len(data) == 0: non_school_val += 1\n",
    "    else: school_val += 1\n",
    "        \n",
    "train_total = len(os.listdir(train_image_folder))\n",
    "val_total = len(os.listdir(val_image_folder))\n",
    "\n",
    "\n",
    "####################   print   ####################\n",
    "print(\"Total images in train :\", train_total)\n",
    "print(\"Total images in val :\", val_total, '\\n')\n",
    "\n",
    "print('Train:')\n",
    "print('school :', school_train)\n",
    "print('non_school :', non_school_train, '\\n')\n",
    "\n",
    "print('Val:')\n",
    "print('school :', school_val)\n",
    "print('non_school :', non_school_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b04fdb",
   "metadata": {},
   "source": [
    "# 2. **YOLOv5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba5f14",
   "metadata": {},
   "source": [
    "## 2.1. Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov5_folder = \"yolov5\"\n",
    "hyp_dir = os.path.join(yolov5_folder, \"data/hyps/hyp.scratch-med.yaml\")\n",
    "\n",
    "with open(hyp_dir, \"r\") as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "config['mosaic'] = 0.0\n",
    "config['scale'] = 0.0\n",
    "config['flipud'] = 0.5\n",
    "config['degrees'] = 0.5\n",
    "config['mixup'] = 0.0\n",
    "\n",
    "# write yaml file\n",
    "with open(hyp_dir, 'w') as outfile:\n",
    "    yaml.dump(config, outfile, default_flow_style=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e030d0",
   "metadata": {},
   "source": [
    "## 2.2. Create yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3133a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = dataset_root\n",
    "os.listdir(DATASET_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml = dict(\n",
    "    train = f\"{DATASET_FOLDER}/train\",\n",
    "    val = f\"{DATASET_FOLDER}/val\",\n",
    "\n",
    "    nc = 1,\n",
    "    names = ['school']\n",
    ")\n",
    "\n",
    "yaml_dir = os.path.join(DATASET_FOLDER, 'data.yaml')\n",
    "\n",
    "# write data.yaml file\n",
    "with open(yaml_dir, 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b5ee4",
   "metadata": {},
   "source": [
    "## 2.3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a36c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 150\n",
    "IMG_SIZE = 256\n",
    "\n",
    "EPOCHS = 50\n",
    "project_folder = '/home/username/Desktop/school_detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7137c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5\n",
    "\n",
    "!python train.py --img {IMG_SIZE} \\\n",
    "                 --batch {BATCH_SIZE} \\\n",
    "                 --epochs {EPOCHS} \\\n",
    "                 --data {yaml_dir} \\\n",
    "                 --weights yolov5l.pt \\\n",
    "                 --save-period 1 \\\n",
    "                 --project {project_folder} \\\n",
    "                 --hyp {hyp_dir}\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c470078",
   "metadata": {},
   "source": [
    "## 2.4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6885ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_FILE = 'my_weights_dir/best.pt'\n",
    "\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 150\n",
    "IOU_THRESH = 0.2\n",
    "CONF_THRESH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5\n",
    "\n",
    "!python val.py --img {IMG_SIZE} \\\n",
    "                 --batch-size {BATCH_SIZE} \\\n",
    "                 --conf-thres {CONF_THRESH} \\\n",
    "                 --data {yaml_dir} \\\n",
    "                 --weights {WEIGHT_FILE} \\\n",
    "                 --iou-thres {IOU_THRESH} \\\n",
    "                 --task val \\\n",
    "                 --project {project_folder} \\\n",
    "                 --save-txt \\\n",
    "                 --save-conf \\\n",
    "                 --name infer_outputs\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080de30",
   "metadata": {},
   "source": [
    "## 2.5. Move training output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9dbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = os.path.join(project_folder, 'exp/weights')\n",
    "\n",
    "dest_folder = os.path.join(project_folder, 'all_trained_weights')\n",
    "os.makedirs(dest_folder, exist_ok = True)\n",
    "\n",
    "item_list = os.listdir(weights_folder)\n",
    "\n",
    "# move weight files from training_outputs folder to a separate folder\n",
    "for item in item_list:\n",
    "    src = os.path.join(weights_folder, item)\n",
    "    dest = os.path.join(dest_folder, item)\n",
    "    shutil.move(src, dest)\n",
    "\n",
    "# copy best.pt and last.pt weight files to a folder\n",
    "weights = ['best.pt', 'last.pt']\n",
    "\n",
    "best_last_folder = os.path.join(project_folder, 'best_last_weights')\n",
    "os.makedirs(best_last_folder, exist_ok = True)\n",
    "\n",
    "os.listdir(dest_folder)\n",
    "\n",
    "for w in weights:\n",
    "    src = os.path.join(dest_folder, w)\n",
    "    dest = os.path.join(best_last_folder, w)\n",
    "    shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41664bc2",
   "metadata": {},
   "source": [
    "- **best.pt** and **last.pt** can be found in **\"best_last_folder\"**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
